<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Abhishek Panigrahi</title>

    <meta name="author" content="Abhishek Panigrahi">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
    <style>
      .paper-entry {
        display: flex;
        align-items: flex-start;       /* top-align image and text */
        margin-bottom: 25px;
      }
      .paper-thumb img {
        width: 300px;
        border-radius: 8px;
        box-shadow: 0 2px 6px rgba(0,0,0,0.1);
        margin-right: 36px;
      }
      .paper-info {
        flex: 1;
        text-align: left;              /* left-align text with image */
        line-height: 1.4;
      }
      .papertitle {
        font-weight: 600;
        font-size: 1em;
      }
    </style>

  </head>
  

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Abhishek Panigrahi
                </p>
                <p>
                  I am a fifth year graduate student in the Computer Science department at Princeton University, fortunate to be advised by Prof. Sanjeev Arora. Previously, I was a Research Fellow at Microsoft Research Lab - India where I worked with Dr. Harsha Vardhan Simhadri and Dr. Navin Goyal. Prior to the fellowship, I attended IIT Kharagpur where I obtained my B.Tech. in Computer Science and Engineering in 2018.
                </p>
                <p>
                  I am an <strong>Apple AI/ML Ph.D. scholar</strong> and a <strong>Siebel scholar</strong> for the academic year 2025-26.
                </p>
                <p style="text-align:center">
                  <a href="mailto:ap34@princeton.edu">Email</a> &nbsp;/&nbsp;
                  <a href="data/CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=oMhp8p8AAAAJ&hl=en&authuser=1">Scholar</a> &nbsp;/&nbsp;
                </p>
                <p style="color:#D2691E;">
                  I will be on the <strong>job market for 2026</strong>. Please reach out if you think my background and experience could be a good fit for your organization.
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/image.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/image.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  My research aims to move beyond the paradigm of “more compute, better results” toward “targeted compute, stronger generalization.”
                  I study what makes language models truly adaptable to more difficult tasks beyond human supervision -- which I refer to as strong generalization.
                  My goal is to identify and optimize the components of the training pipeline that give rise to robust, adaptable reasoning in language models.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          </tbody></table>

					<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Representative Works</h2>
              </td>
            </tr>
          </tbody></table>
          <!-- Paper list -->
          <table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:32px;"><tbody>



          <div class="paper-entry">
            <a href="https://arxiv.org/abs/2503.01821" class="paper-thumb">
              <img src="images/GRACE.png" alt="GRACE figure">
            </a>
            <div class="paper-info">
              <span class="papertitle">In Good GRACES: Principled Teacher Selection for Knowledge Distillation</span><br>
              <strong>Abhishek Panigrahi</strong>, Bingbin Liu, Sadhika Malladi, Sham Kakade, Surbhi Goel<br>
              <em>In submission</em>
            </div>
          </div>


          <tr>
            <td style="padding:8px;width:80%;vertical-align:middle">
                <span class="papertitle">STAT: Skill-Targeted Adaptive Training</span>
              <br>
              Yinghui He*, <strong>Abhishek Panigrahi</strong>*, Yong Lin, Sanjeev Arora
              <br>
              <em>In Submission</em> 
              <p></p>
            </td>
          </tr>


          <div class="paper-entry">
            <a href="https://arxiv.org/abs/2503.01821" class="paper-thumb">
              <img src="images/cel.png" alt="Context-Enhanced Learning figure">
            </a>
            <div class="paper-info">
              <span class="papertitle">On the Power of Context-Enhanced Learning in LLMs</span><br>
              Xingyu Zhu*, <strong>Abhishek Panigrahi</strong>*, Sanjeev Arora<br>
              <em>International Conference on Machine Learning (ICML 2025)</em>
              <span style="color:red;">(Spotlight)</span><br>
              <a href="https://arxiv.org/abs/2503.01821">arXiv</a> /
              <a href="https://github.com/princeton-pli/Context-Enhanced-Learning">code</a>
            </div>
          </div>
          
          <div class="paper-entry">
            <a href="https://arxiv.org/abs/2503.01821" class="paper-thumb">
              <img src="images/vlm.png" alt="VLM figure">
            </a>
            <div class="paper-info">
              <span class="papertitle">Generalizing from SIMPLE to HARD Visual Reasoning: Can We Mitigate Modality Imbalance in VLMs?</span><br>
              Simon Park*, <strong>Abhishek Panigrahi</strong>*, Catherine Cheng*, Dingli Yu, Anirudh Goyal, Sanjeev Arora
              <br>
              <em>International Conference on Machine Learning (ICML 2025)</em> 
              <a href="https://arxiv.org/abs/2501.02669">arXiv</a> /
              <a href="https://github.com/princeton-pli/VLM_S2H">code</a>
            </div>
          </div>


          
          

        <div class="paper-entry">
          <a href="https://openreview.net/forum?id=wPMRwmytZe" class="paper-thumb">
            <img src="images/Progressive_distil.png" alt="VLM figure">
          </a>
          <div class="paper-info">
            <span class="papertitle">Progressive distillation induces an implicit curriculum</span><br>
            <strong>Abhishek Panigrahi</strong>*, Bingbin Liu*, Sadhika Malladi, Andrej Risteski, Surbhi Goel
           <br>
            <em>International Conference on Learning Representations (ICLR 2025)</em> <span style="color:red;">(Oral)</span>
            <a href="https://openreview.net/forum?id=wPMRwmytZe">Openreview</a>
              /
              <a href="https://github.com/abhishekpanigrahi1996/ProgressiveDistillation">code</a>
              /
              <a href="https://unprovenalgos.github.io/progressive-distillation">blog</a>
          </div>
        </div>

        

        <tr>
          <td style="padding:8px;width:80%;vertical-align:middle">
              <span class="papertitle">Efficient stagewise pretraining via progressive subnetworks</span>
            <br>
             <strong>Abhishek Panigrahi</strong>*, Nikunj Saunshi*, Kaifeng Lyu, Sobhan Miryoosefi, Sashank Reddi, Satyen Kale, Sanjiv Kumar
            <br>
            <em> International Conference on Learning Representations (ICLR 2025)</em> 
            <br>
            <a href="https://openreview.net/forum?id=rkgfdeBYvH">Openreview</a>
            <p></p>
          </td>
        </tr>


        <tr>
          <td style="padding:8px;width:80%;vertical-align:middle">
              <span class="papertitle">Task-specific skill localization in fine-tuned language models</span>
            <br>
             <strong>Abhishek Panigrahi</strong>*, Nikunj Saunshi*, Haoyu Zhao, Sanjeev Arora
            <br>
            <em>International Conference of Machine Learning (ICML 2023)</em>
            <br>
            <a href="https://proceedings.mlr.press/v202/panigrahi23a.html">PMLR</a>
            /
            <a href="https://github.com/abhishekpanigrahi1996/Skill-Localization-by-grafting">code</a>
            <p></p>
          </td>
      </tr>

        <tr>
          <td style="padding:8px;width:80%;vertical-align:middle">
              <span class="papertitle">Understanding Gradient Descent on the Edge of Stability in Deep Learning</span>
            <br>
             Sanjeev Arora, Zhiyuan Li, <strong>Abhishek Panigrahi</strong> (alphabetical)
            <br>
            <em>International Conference of Machine Learning (2022)</em>  <span style="color:red;">(Spotlight)</span>
            <br>
            <a href="https://proceedings.mlr.press/v162/arora22a.html">PMLR</a>
            /
            <a href="https://github.com/abhishekpanigrahi1996/Edge_of_Stability">code</a>
            <p></p>
          </td>
        </tr>


      </tbody></table>



      <table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
        <tr>
          <td>
            <h2>Other representative works</h2>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      
      <table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:32px;"><tbody>

        
        <tr>
          <td style="padding:8px;width:80%;vertical-align:middle">
              <span class="papertitle">Trainable Transformer in Transformer</span>
            <br>
             <strong>Abhishek Panigrahi</strong>*, Sadhika Malladi*, Mengzhou Xia, Sanjeev Arora
            <br>
            <em> International Conference of Machine Learning (ICML 2024)</em> 
            <br>
            <a href="https://openreview.net/forum?id=JcxlFe2fGC">Openreview</a>
            /
            <a href="https://github.com/abhishekpanigrahi1996/transformer_in_transformer">Code</a>
            <p></p>
          </td>
        </tr>

        <tr>
          <td style="padding:8px;width:80%;vertical-align:middle">
              <span class="papertitle">Do transformers parse while predicting the masked word?</span>
            <br>
             Haoyu Zhao*, <strong>Abhishek Panigrahi</strong>*, Rong Ge, Sanjeev Arora
            <br>
            <em> Empirical Methods in Natural Language Processing (EMNLP 2023)</em> 
            <br>
            <a href="https://arxiv.org/abs/2303.08117">Arxiv</a>
            <p></p>
          </td>
        </tr>

        <tr>
          <td style="padding:8px;width:80%;vertical-align:middle">
              <span class="papertitle">Effect of Activation Functions on the Training of Overparametrized Neural Nets</span>
            <br>
             <strong>Abhishek Panigrahi</strong>*, Abhishek Shetty*, Navin Goyal
            <br>
            <em> International Conference on Learning Representations (ICLR 2020)</em> 
            <br>
            <a href="https://openreview.net/forum?id=rkgfdeBYvH">Openreview</a>
            <p></p>
          </td>
        </tr>


        <tr>
          <td style="padding:8px;width:80%;vertical-align:middle">
              <span class="papertitle">Word2Sense: Sparse interpretable word embeddings</span>
            <br>
              <strong>Abhishek Panigrahi</strong>, Harsha Vardhan Simhadri, Chiranjib Bhattacharyya
            <br>
            <em> Association for Computational Linguistics (ACL 2019)</em>  <span style="color:red;">(Oral)</span>
            <br>
            <a href="https://aclanthology.org/P19-1570/">ACL</a>
            /
            <a href="https://github.com/abhishekpanigrahi1996/Word2Sense">code</a>
            <p></p>
          </td>
        </tr>

        </td>
      </tr>
    </table>
  </body>
</html>
